


import pandas as pd
import numpy as np
pd.set_option('max_colwidth', 20)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 50)
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
plt.rcParams['figure.figsize'] = (12,8)
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = 'all'
from ipywidgets import interact
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report


data = pd.read_csv('Documents\Crop_recommendation.csv')
data.head()


data.shape


data.info()


data.isnull().sum()


plt.figure(figsize=(8,4))
sns.boxplot(data)


Q1=data['P'].quantile(0.25)
Q3=data['P'].quantile(0.75)
IQR=Q3-Q1
filter=(data['P']>=Q1-1.5*IQR) & (data['P']<=Q3+1.5*IQR)
data=data.loc[filter]


print("Summer crops")
print(data[(data['temperature'] > 30) & (data['humidity'] > 50)]['label'].unique())
print()
print("Winter crops")
print(data[(data['temperature'] < 20) & (data['humidity'] > 30)]['label'].unique())
print()
print("Rainy crops")
print(data[(data['rainfall'] > 200) & (data['humidity'] > 50)]['label'].unique())


y = data['label']
x = data.drop(['label'], axis = 1)
print("Shape of x", x.shape)
print("Shape of x = y", y.shape)


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
print("The shape of x train", x_train.shape)
print("The shape of x test", x_test.shape)
print("The shape of y train", y_train.shape)
print("The shape of y test", y_test.shape)





# 1. Univariate Analysis
# Histogram
sns.set(style="whitegrid")

features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']
titles = ['Ratio of Nitrogen', 'Ratio of Phosphorus', 'Ratio of Potassium',
          'Ratio of Temperature', 'Ratio of Humidity', 'Ratio of pH', 'Ratio of Rainfall']
colors = ['navy', 'skyblue', 'violet', 'green', 'orange', 'red', 'yellow']

fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

for i, feature in enumerate(features):
    sns.histplot(data[feature], kde=True, ax=axes[i], color=colors[i])
    axes[i].set_title(titles[i])

fig.delaxes(axes[-1])

plt.suptitle("Distribution of agricultural conditions", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()


# 2. Bivariate Analysis
# Scatter Plot
plt.subplot(2, 4, 7)
sns.scatterplot(x=data['humidity'], y=data['label'],alpha = 0.5, c = 'red', edgecolors = 'black')


# 3. Multivariate Analysis
# Pair Plot
features = ['N', 'P', 'K', 'label']
sns.pairplot(data[features], hue = 'label')
plt.suptitle("Pair Plot of Crop Features", y = 1.02)
plt.show()


# Heat Map
numeric_df = data.select_dtypes(include='number')
correlation_matrix = numeric_df.corr()
plt.figure(figsize=(10,6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Heatmap of Numerical Crop Features")
plt.show()


# Count Plot
sns.countplot(data)


# 4. Descriptive Analysis
data.describe()





# 1. K-Means
plt.rcParams['figure.figsize'] = (10, 4)
wcss = []

for i in range(1, 11):
    km = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    km.fit(x)  # x should be your selected feature set
    wcss.append(km.inertia_)

plt.plot(range(1, 11), wcss)
plt.title("The Elbow Method", fontsize=20)
plt.xlabel("No of clusters")
plt.ylabel("WCSS")
plt.show()


km = KMeans(n_clusters=4,init="k-means++",max_iter=300,n_init=10,random_state=0)
y_means=km.fit_predict(x)

a=data['label']
y_means=pd.DataFrame(y_means)
z=pd.concat([y_means,a],axis=1)
z=z.rename(columns={0:'cluster'})

print("lets check the results after applying the K-Means clustering analysis \n")
print("Crops in First cluster:",z[z['cluster']==0]['label'].unique())
print()
print("Crops in Second cluster:",z[z['cluster']==1]['label'].unique())
print()
print("Crops in Third cluster:",z[z['cluster']==2]['label'].unique())
print()
print("Crops in Fourth cluster:",z[z['cluster']==3]['label'].unique())


# 2. Logistic Regression Model
model = LogisticRegression()
model.fit(x_train,y_train)
y_pred = model.predict(x_test)


# 3. Evaluating the performance of the model and saving the model
plt.rcParams["figure.figsize"] = (10,10)
cm = confusion_matrix(y_test,y_pred)
sns.heatmap(cm,annot = True, cmap = 'Wistia')
plt.title("Confusion matrix for logistic regression", fontsize = 15)
plt.show()


# 4. Predict the best crop according to the given parameters
prediction = model.predict((np.array([[105,35,40,25,64,7,160]])))
print("The suggested crop for given climatic condition is: ",prediction)


import pickle
pickle.dump(model, open(r'C:\Users\psiri\Desktop\OptiCrop\model.pkl', 'wb'))
